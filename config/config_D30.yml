model_name: NIERT  # choose from NIERT, TransformerRecon
# model_name: TransformerRecon  # choose from NIERT, TransformerRecon
# model_name: ConditionalNeuralProcess  # choose from NIERT, TransformerRecon
# model_name: AttentiveNeuralProcess  # choose from NIERT, TransformerRecon

dataset_type: D30
# cfg_dim_input: 101
cfg_dim_input: 31
cfg_dim_output:

# dataset path
data_root: ""
train_path: ""
test_path: ""

# batch_size: 128
batch_size: 128
# batch_size: 256
# batch_size: 512
# max_epochs: 100
# max_epochs: 160
max_epochs: 100
lr: 0.0001
lr_decay:

# which gpu to use
# gpu: 4 # 0 cpu, 1 gpu:0, 2 gpu:1
# gpu: 2 # 0 cpu, 1 gpu:0, 2 gpu:1
gpu: 1 # 0 cpu, 1 gpu:0, 2 gpu:1

val_check_interval: 1.0

# num_workers in dataloader
# num_workers: 4
num_workers: 0

model_arch_cfg:
  # layers: 2
  layers: 5
  dim_hidden: 128
  dim_inner: 128
  num_heads: 8

nesymres_data_cfg:
  dataset_train:
    total_variables: #Do not fill
    total_coefficients: #Do not fill
    max_number_of_points: 50  # 1/10
    type_of_sampling_points: logarithm
    predict_c: True
    fun_support:
      max: 1.0
      min: -1.0
    constants:
      num_constants: 3
      additive:
        max: 2
        min: -2
      multiplicative:
        max: 2
        min: -2

  dataset_val:
    total_variables: #Do not fill
    total_coefficients: #Do not fill
    max_number_of_points: 50
    type_of_sampling_points: logarithm
    predict_c: True
    fun_support:
      max: 1.0
      min: -1.0
    constants:
      num_constants: 3
      additive:
        max: 2
        min: -2
      multiplicative:
        max: 5
        min: 0.1

  dataset_test:
    total_variables: #Do not fill
    total_coefficients: #Do not fill
    max_number_of_points: 50
    type_of_sampling_points: logarithm
    predict_c: True
    fun_support:
      max: 1.0
      min: -1.0
    constants:
      num_constants: 3
      additive:
        max: 2
        min: -2
      multiplicative:
        max: 5
        min: 0.1
